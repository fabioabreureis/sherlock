#!/bin/bash

while getopts b:j:c:n: flag
do
    case "${flag}" in
        b) readonly BENCHMARK_TOOL=${OPTARG};;
        j) readonly JOB_TYPE=${OPTARG};;
        c) readonly CONFIG_FILE=${OPTARG};;
        n) readonly RUN_NAME=${OPTARG};;
    esac
done

if [[ -z ${BENCHMARK_TOOL} || -z ${JOB_TYPE} ]]; then
  echo "Usage : $0 -b (benchmark tool) <sysbench or pgbench> -j (job type) <prepare, run or cleanup(sysbench only)> -c config file via full path [-n <optional dir name to keep run logs>]"
  exit 1
fi

source ${CONFIG_FILE}

declare -A jobs_pods
declare -A worker_rbd


if [ "$(uname -s)" == "Linux" ];then
  if [[ "${WORKERS_LIST_FILE}" == "${SDS_LIST_FILE}" ]]; then
    mapfile -t worker_node_array < <(cat ${WORKERS_LIST_FILE})
  else
    mapfile -t worker_node_array < <(cat ${WORKERS_LIST_FILE})
    mapfile -t sds_node_array < <(cat ${SDS_LIST_FILE})
  fi
else
  if [[ "${WORKERS_LIST_FILE}" == "${SDS_LIST_FILE}" ]]; then
    declare -a worker_node_array
    while IFS= read -r line; do worker_node_array+=("$line"); done < <(cat ${WORKERS_LIST_FILE})
  else
    declare -a worker_node_array
    while IFS= read -r line; do worker_node_array+=("$line"); done < <(cat ${WORKERS_LIST_FILE})
    declare -a sds_node_array
    while IFS= read -r line; do sds_node_array+=("$line"); done < <(cat ${SDS_LIST_FILE})
  fi
fi

function mydate()
{
 date +%Y%m%d:%H:%M:%S:
}

function get_rbd_list()
{
  declare -A pvc_array
  for ((j=1; j<=${DB_PER_WORKER}*${NUMBER_OF_WORKERS}; j++))
  do
    deployment_name=${DB_POD_PREFIX}-${j}
    claim_name=$(oc get deployment ${deployment_name} -o yaml |grep claimName|awk '{print $2}')
    volume_name=$(oc get pvc ${claim_name} --no-headers -o custom-columns=":spec.volumeName")
    pvc_array[${j}]=${volume_name}
  done
  for node_name in $(cat $WORKERS_LIST_FILE)
  do
    local_node_name=$(oc get node ${node_name} -o jsonpath='{.metadata.labels.kubernetes\.io/hostname}')
    rbd_line=""
    node_pvc=$(oc debug node/${node_name} -- lsblk | grep rbd | awk '{print $1"@@"$7}')
    for lsblk_line in $(echo ${node_pvc})
    do
      pvc="pvc-$(echo $lsblk_line | awk -F'@@' '{print $2}' | awk -F"pvc-" '{print $2}' | tr -d '/mount')"
      for pvc_volume in ${pvc_array[@]}
      do
        if [[ "${pvc}" == "${pvc_volume}" ]]; then
          rbd_line+=" $(echo $lsblk_line | awk -F'@@' '{print $1}')"
        fi
      done
    done
    rbd_line=${rbd_line#?}
    worker_rbd[${local_node_name}]=${rbd_line}
  done
}

function run_db_workload()
{
  local node_name=$(oc get node ${node_name} -o jsonpath='{.metadata.labels.kubernetes\.io/hostname}')
  local db_ip="${1}"
  local node_type="${2}"
  if [[ "${BENCHMARK_TOOL}" == "sysbench" ]]; then
    run_command="./run_sysbench ${JOB_TYPE} ${WORKLOAD_RUNTIME} ${THREADS} ${SYSBENCH_READ_ONLY} ${SYSBENCH_WRITE_ONLY} ${db_ip} ${OUTPUT_INTERVAL} ${SYSBENCH_ROWS_IN_TABLE} ${SYSBENCH_NUMBER_OF_TABLES} ${DB_TYPE} ${DB_USERNAME} ${DB_PASSWORD} ${DB_NAME} ${SYSBENCH_NUMBER_OF_INSERTS} ${SYSBENCH_NUMBER_OF_UPDATES} ${SYSBENCH_NUMBER_OF_NON_INDEX_UPDATES}"
  else
    if [[ "${JOB_TYPE}" == "prepare" ]]; then
      run_command="./run_pgbench ${JOB_TYPE} ${db_ip} ${CLIENTS} ${THREADS} ${PGBENCH_RUN_TYPE} ${PGBENCH_RUN_TYPE_VAR} ${PGBENCH_VACUUM} ${PGBENCH_QUIET} ${PGBENCH_SCALE} ${DB_USERNAME} ${DB_PASSWORD} ${DB_NAME} ${OUTPUT_INTERVAL} ${PGBENCH_READ_ONLY}"
    else
      run_command="./run_pgbench ${PGBENCH_WORKLOAD_TYPE} ${db_ip} ${CLIENTS} ${THREADS} ${PGBENCH_RUN_TYPE} ${PGBENCH_RUN_TYPE_VAR} ${PGBENCH_VACUUM} ${PGBENCH_QUIET} ${PGBENCH_SCALE} ${DB_USERNAME} ${DB_PASSWORD} ${DB_NAME} ${OUTPUT_INTERVAL} ${PGBENCH_READ_ONLY}"
    fi
  fi
  if ${DEBUG}; then echo "$(mydate)-run_command=${run_command}";fi
  job_name=$(cat <<EOF | ${KUBE_CMD} create -f -
apiVersion: batch/v1
kind: Job
metadata:
  generateName: ${BENCHMARK_TOOL}-${JOB_TYPE}-${deployment_name}-${RUN_NAME}-
spec:
  template:
    spec:
      restartPolicy: OnFailure
      nodeSelector:
        kubernetes.io/hostname: ${node_name}
      containers:
        - image: quay.io/sagyvolkov/benchmark-container:0.87
          name: ${BENCHMARK_TOOL}-${JOB_TYPE}
          resources:
            limits:
              memory: 2Gi
          command:
                - "bash"
                - "-c"
                - >
                  ${run_command}
EOF
)
job_name=$(echo ${job_name} | awk '{print $1}')
workload_pod_name=$(${KUBE_CMD} describe ${job_name} | grep "Created pod:" | awk -F "Created pod: " '{print $2}')
}

function run_stats()
{
  local node_name=$(oc get node ${node_name} -o jsonpath='{.metadata.labels.kubernetes\.io/hostname}')
  local node_type="${1}"
  job_name=$(cat <<EOF | ${KUBE_CMD} create -f -
apiVersion: batch/v1
kind: Job
metadata:
  generateName: stats-${RUN_NAME}-${node_type}-${node_name}-
spec:
  template:
    spec:
      hostNetwork: true
      restartPolicy: Never
      nodeSelector:
        kubernetes.io/hostname: ${node_name}
      containers:
        - image: quay.io/sagyvolkov/stats-container:0.94
          name: stats-${RUN_NAME}
          resources:
            limits:
              memory: 64Mi
              cpu: 0.1
          command:
              - "bash"
              - "-c"
              - echo "${SDS_NETWORK_INTERFACES}" > /tmp/ocs_network_interfaces; echo "${SDS_DEVICES}" > /tmp/ocs_devices; ./run_all ${STATS_INTERVAL} ${STATS_COUNT} ${node_type}
EOF
)
job_name=$(echo ${job_name} | awk '{print $1}')
stats_pod_name=$(${KUBE_CMD} describe ${job_name} | grep "Created pod:" | awk -F "Created pod: " '{print $2}')
}

function cordon_control()
{
  local cordon_command=${1}
  local cordon_node=${2}
  if [[ "${cordon_command}" == "cordon" ]]; then
    [[ "${KUBE_CMD}" == "oc" ]] && ${KUBE_CMD} adm cordon ${cordon_node} || ${KUBE_CMD} cordon ${cordon_node}
  else
    [[ "${KUBE_CMD}" == "oc" ]] && ${KUBE_CMD} adm uncordon ${cordon_node} || ${KUBE_CMD} uncordon ${cordon_node}
  fi
}

function stats_collect()
{
  local node_type=${1}
  shift 1
  local local_array=("$@")
  for node_name in ${local_array[@]}
  do
    echo "$(mydate) Starting to collect stats on ${node_type} node ${node_name}..."
    run_stats "${node_type}" "${local_array[@]}"
    jobs_pods[${job_name}]=${stats_pod_name}
  done
}

function calculate_rbd_utilization()
{
  local file_name=${1}
  local rbd_device="${2}"
  for device_name in ${rbd_device}
  do
      let r_s=0
      let w_s=0
      let util=0
      let number_of_inputs=0
      while read x
      do
        r_s=$(echo "$r_s + $(echo ${x}|awk -F, '{print $1}')"|bc)
        w_s=$(echo "$w_s + $(echo ${x}|awk -F, '{print $2}')"|bc)
        util=$(echo "$util + $(echo ${x}|awk -F, '{print $3}')"|bc)
        let number_of_inputs++
      done < <(grep ${device_name} ${file_name} | awk '{print $2","$8","$23}')
      avg_r_s=$(echo "scale=2;$r_s/$number_of_inputs"|bc)
      avg_w_s=$(echo "scale=2;$w_s/$number_of_inputs"|bc)
      avg_util=$(echo "scale=2;$util/$number_of_inputs"|bc)
      echo "NODE: ${node_ip}, AVERAGE RBD device ${device_name} read/s: ${avg_r_s}, write/s: ${avg_w_s}, utilization%: ${avg_util}" >> ${file_name}
  done
}

if [[ "${JOB_TYPE}" == "run" && "${STATS}" == "true" ]]; then
  oc adm policy add-scc-to-user hostnetwork -n${PROJECT_NAME} -z default
  stats_collect worker ${worker_node_array[@]}
  [[ ${#sds_node_array[@]} -ne 0 ]] && stats_collect ocs ${sds_node_array[@]}
fi

for ((j=1; j<=${DB_PER_WORKER}*${NUMBER_OF_WORKERS}; j++))
do
  node_number=$((j%NUMBER_OF_WORKERS))
  node_name=${worker_node_array[${node_number}]}
  deployment_name=${DB_POD_PREFIX}-${j}
  if [[ "${DB_TYPE}" == "pgsql" ]]; then
    database_ip=$(${KUBE_CMD} get svc -n ${PROJECT_NAME} ${deployment_name} -o jsonpath='{.spec.clusterIP}')
  else
    database_ip=$(${KUBE_CMD} get pod -l app=${deployment_name} -o jsonpath='{.items[].status.podIP}')
  fi
  echo "$(mydate) Starting ${BENCHMARK_TOOL} job for ${JOB_TYPE} in deployment ${deployment_name} with database ip ${database_ip} ..."
  #sleep 5
  run_db_workload ${database_ip}
  jobs_pods[${job_name}]=${workload_pod_name}
  echo "$(mydate) ${job_name} is using ${BENCHMARK_TOOL} pod ${workload_pod_name} on node ${node_name}"
done

if [[ "${JOB_TYPE}" == "run" ]];then
  if [[ -z ${RUN_NAME} ]]; then
    RUN_NAME="${BENCHAMRK_TOOL}-${JOB_TYPE}-$(date +%s)"
  fi
  if [[ ! -d "${RUN_NAME}" ]]; then
    mkdir -p "$RUN_NAME"
  fi

  cp ${CONFIG_FILE} ${RUN_NAME}/
  job_list=""

  for i in "${!jobs_pods[@]}"
  do
    job_list="${job_list} ${i}"
  done
  echo "$(mydate) Waiting for jobs to complete ..."
  ${KUBE_CMD} wait --for=condition=complete ${job_list} --timeout=4000s

  echo "$(mydate) All jobs are done, getting logs ..."

  for i in "${!jobs_pods[@]}"
  do
    ${KUBE_CMD} logs ${jobs_pods[$i]} > ${RUN_NAME}/${jobs_pods[$i]}.log
  done

  if [[ "${RBD_STATS}" == "true" ]]; then
    echo "$(mydate) Getting list of database RBDs from worker nodes and pods ..."
    get_rbd_list
    for node_ip in ${!worker_rbd[@]}
    do
      file_name=$(ls ${RUN_NAME}/stats-${RUN_NAME}-worker-${node_ip}*.log)
      rbd_device="${worker_rbd[${node_ip}]}"
      calculate_rbd_utilization ${file_name} "${rbd_device}"
    done
  fi
fi
